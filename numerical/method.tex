\chapter{Méthodes numériques}
\label{chap-sim}

En 1949, Metropolis \cite{metropolis_monte_1949} découvre une méthode pour calculer via des simulations numériques de Monte Carlo, la moyenne d'observables statistiques. Si $Q$ est une quantité observable appartenant à un système statistique, comme l'énergie interne ou la densité moyenne de particules par site, alors la moyenne est calculée en pondérant la valeur de l'observable sur toutes les configurations $C$ du système par rapport au poids statistique de ces configurations. Si l'on considère le système en équilibre thermodynamique alors chaque configuration $C$ suit une distribution de Gibbs-Boltzmann, et la moyenne $<Q>$ est vaut
\begin{align}
    <Q> = \frac{\sum_{C} Q(C) \exp(-\beta E(C))}{\sum_{C} \exp(-\beta E(C))}
\end{align}
Pour un système SOS de taille $100\times100$ par exemple, petit par rapport à la limite thermodynamique comme discuté avec la figure \ref{fig-thermo-libre}, il existe $100^{100}$ configurations possibles, bien qu'une simulation numérique ne puisse explorer qu'environ $10^8$ configurations différentes en un temps CPU raisonnable.
Les modèles sur réseau se prêtent parfaitement aux simulations numériques de Monte Carlo, où le but est de calculer la valeur moyenne des observables telles que l'énergie interne ou la densité moyenne de particule par site. Toutes ces quantités peuvent être calculées directement pour le modèle SOS dans l'ensemble grand-canonique à l'aide des valeurs propres de la matrice de transfert, mais il est impossible d'utiliser une telle méthode dans l'ensemble canonique, comme expliqué dans le chapitre précédent.

Dans ce chapitre, nous commençons par expliquer le principe des simulations de Monte Carlo Metropolis, et comment choisir l'ensemble thermodyique de la simulation numérique. En plus d'étudier l'ensemble canonique, les simulations numériques offrent la possibilité d'étudier les régimes hors équilibre, dont nous justifierons la validité.
Nous finirons le chapitre par expliquer comment accélérer la vitesse de simulation grâce à la parallélisation, ainsi que d'autres astuces de programmation, en insistant sur les écueils techniques à éviter. 

Je remercie le Mésocentre de Calcul Intensif Aquitain (MCIA)\footnote{\url{https://redmine.mcia.fr/projects/mcia}} sur lequel j'ai effectué la très grande majorité de mes simulations numériques. 
L'intégralité du code produit pour cette thèse est accessible sur Github \footnote{\url{https://github.com/Bulbille/Curta}} sous la licence Creative Commons BY 3.0 \footnote{\url{https://creativecommons.org/licenses/by/3.0/fr/}}. Les simulations numériques ont été codées en C++, la parallélisation avec la librairie MPI, l'automatisation du lancement des jobs en Bash, et la visualisation des données ainsi que les diagonalisations des matrices de transfert sous Python.

{\color{red} actuellement, est-ce que j'ai le droit de diffuser librement mon code ? Le CNRS autorise la libre diffusion du code ?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Algorithme de Monte Carlo Metropolis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Les simulations de Monte Carlo explorent l'espace des configurations de manière aléatoire \cite{newman_monte_1999} avec une probabilité $p(C$ que nous définirons plus tard. En choisissant $M$ états ${C_0,...,C_M}$, l'estimateur $Q_M$ de $Q$ est donnée par
\begin{align}
    Q_M = \frac{\sum_{i=0}^M Q(C_i) p(C_i)^{-1} \exp(-\beta E(C_i))}{\sum_{i=0}^M  p(C_i)^{-1} \exp(-\beta E(C_i))}
\end{align}
Lorsque $M$ augmente, l'estimateur devient une estimation de plus en plus précise de $<Q>$, jusqu'à la limite $Q_{M\to \infty} = <Q>$. Si l'on choisit les configurations sur lesquelles on échantillone le système selon la distribution à l'équilibre de Gibbs-Boltzmann $p(\nu) = Z^{-1} e^{-\beta E(C)}$, alors l'éstimateur de $<Q>$ devient
\begin{align}
    Q_M = \frac{1}{M} \sum_{i=0}^M Q(C_i)
\end{align}
On se pose maintenant la question de savoir comment choisir les configurations afin que chacune apparaisse avec la bonne probabilité de Boltzmann. 

Une dynamique pour les systèmes avec une espace des phases discret peut être construit à partir de chaînes de Markov. On laisse la dynamique évoluer dans un discret noté $n$, et $p_n(C)$ la probabilité que le système soit dans l'état $C$ au temps $n$. Au pas de temps suivant, si le système est dans l'état $C$ il peut sauter vers un autre état $C'$ avec la probabilité de transition $\rho(C\to C')$. Le système au tempst $n+1$ dépend alors uniquement de l'état au temps $n$ : c'est un processus markovien. La probabilité $p_{n+1}(X)$ d'être dans l'état $C$ au temps $n+1$ est possible si le système était dans l'état $C$ au temps $n$ et y reste avec une probabilité $\rho(C\to C)$ , ou s'il est dans un état $C'$ et bouge vers l'état $C$ avec une probabilité $\rho(C'\to C)$. On a alors l'équation maîtresse
\begin{align}
    p_{n+1}(C) =  \rho(C\to C) p_n(C) + \sum_{C'\neq C} \rho(C'\to C) p_n(C')
\end{align}
Puisque $\rho(C' \to C)$ est une probabilité, on a la condition suivante
\begin{align}
    \sum_{C'} \rho(C' \to C) = 1
    \label{norm}
\end{align}
Maintenant, si la dynamique décrit un système physique en interaction avec un  réservoir de chaleur, la distribution à l'équilibre est donnée par
\begin{align}
    p_{eq}(C) = \frac{\exp(-\beta E(C))}{Z}
\end{align}
avec $Z$ la fonction de partition canonique. Puisque la distribution à l'équilibre n'évolue pas au cours du temps, on a
\begin{align}
    p_{eq}(C) =  \rho(C\to C) p_{eq}(C) + \sum_{C'\neq C} \rho(C'\to C)p_{eq}(C')
    \label{p-eq-mc}
\end{align}
Une autre condition que l'on impose à notre chaîne de Markov afin qu'elle génère une probabilité de distribution de Boltzmann après équilibrage, est qu'elle respecte le bilan détaillé. Afin qu'un système respecte le bilan détailĺé, il faut que le taux auquel il fait des transitions vers à partir de n'importe quel état $C$ soit égal. Mathématiquement, cela revient à dire que
\begin{align}
    \sum_{C'} p(C) \rho(C \to C') = \sum_{C'} p(C') \rho(C' \to C)
\end{align}
On peut démontrer que cette relation est équivalente à \cite{newman_monte_1999} 
\begin{align}
    \frac{\rho(C'\to C)}{\rho(C \to C')} = \frac{p(C)}{p(C')} = \frac{\exp(-\beta E(C))}{\exp(-\beta E(C'))}
\end{align} 
En adoptant le bilan détaillé, on voit facilement que la distribution à l'équilibre calculée via \ref{p-eq-mc} redonne bien la distribution de Gibbs-Boltzmann.
Durant une étape de Metropolis, la probabilité pour que la transition $C\to C'$ soit acceptée est 
\begin{align}
    p_a(C\to C')
\end{align}


Systems with a canonical heat bath can be simulated on a computer using an algorithm
obeying detailed balance. For example consider a system of $N$ Ising spins $S_i=\pm1$ interacting via a Hamiltonian $H(S_1, S_2,\cdots S_N)$. We choose $1$ of the spins randomly uniformly with a probability $p=1/N$ and calculate the new energy of the system when the spin, $S_j$ say is changed to $-S_j$. In Metropolis dynamics the probability of accepting the spin flip $p_a(S_j\to -S_j)$ is given by 
\begin{align}
p_a(S_j\to -S_j)
\end{align}
if $H(S_1, S_2,\cdots, -S_j,\cdots S_N) < H(S_1, S_2,\cdots, S_j,\cdots S_N)$ but if $H(S_1, S_2,\cdots, -S_j,\cdots S_N) > H(S_1, S_2,\cdots, S_j,\cdots S_N)$ then the flip is accepted with probability 
\begin{align}
p_a(S_j\to -S_j) = \exp\left[ -\beta\left(H(S_1, S_2,\cdots, -S_j,\cdots S_N) - H(S_1, S_2,\cdots, S_j,\cdots S_N)\right)\right] <1.
\end{align}
The total probability at a given discrete time of changing $S_j$ is thus equal to 
\begin{align}
p(S_j\to -S_j) = \frac{1}{N} p_a(S_j\to -S_j)
\end{align}
as we choose the spin $S_j$ with probability $1/N$. Therefore we have
\begin{align}
\frac{p(S_j\to -S_j)}{p(-S_j\to S_j)} = \frac{p_a(S_j\to -S_j)}{p_a(-S_j\to S_j)}.
\end{align}
In the case where the change $S_j\to -S_j$ lowers the energy we have
\begin{align}
p_a(S_j\to -S_j) =1,
\end{align}
however the reverse move $-S_j\to S_j$ costs energy so 
\begin{align}
p_a(-S_j\to S_j) =\exp\left[ -\beta\left(H(S_1, S_2,\cdots, S_j,\cdots S_N) - H(S_1, S_2,\cdots, -S_j,\cdots S_N)\right)\right],
\end{align}
which gives
\begin{eqnarray}
\frac{p(S_j\to -S_j)}{p(-S_j\to S_j)} &=& \frac{1}{\exp\left[ -\beta\left(H(S_1, S_2,\cdots, S_j,\cdots S_N) - H(S_1, S_2,\cdots, -S_j,\cdots S_N)\right)\right]} \nonumber \\
&=&\frac{ \exp\left[ -\beta H(S_1, S_2,\cdots, -S_j,\cdots S_N)\right]}{\exp\left[ -\beta H(S_1, S_2,\cdots, S_j,\cdots S_N)\right]},
\end{eqnarray}
and so in this case we see that detailed balance is respected. In the case of a move which increases the energy it is easy to see that detailed balance is again respected.  

If we consider a case where the spins $+$ represent one type of particle and the $-$ another type and insist that the total  chemical composition remains the same the above dynamics is not correct as you cannot convert a $+$ into a $-$ and vice-a-versa. However a $+$ next to a $-$ can change places. Kawasaki dynamics chooses a neighbouring pair of $+$ and $-$ and tries to switch their positions, e.g. $.+-.\to .-+.$,  the move is accepted with probability $1$ if the energy change $\Delta E<0$  and with probability $p_a=\exp\left(-\beta\Delta E\right)$ if $\Delta E>0$.

Practically in a computer program if $\Delta E >0$ one draws a uniformly distributed random
number $r\in[0,1]$ (for example {\tt rand} in Fortran and Matlab), if $r< p_a $ the move accepted but if $r>p_a$ it is refused and the system stays in its initial state.



\section{Suite}


qui définit la fonction de partition $\mZ$. Dans un algorithme de Metropolis, on met à jour le micro-état en prenant un site $i$ au hasard
\footnote{L'utilisation d'un générateur de nombre aléatoire (\textit{pRNG}) efficace est primordial. Il est déconseillé d'utiliser le générateur standard \textit{default\_random\_engine} de la librairie C++ \textit{rand} et conseillé d'opter pour des générateurs \textit{sfc64} ou \textit{xoroshiro}. Pour un pRNG booléen performant, voir \url{https://martin.ankerl.com/2018/12/08/fast-random-bool/}. Pour accélérer encore plus les calculs, ne pas oublier d'utiliser le flag d'optimisation \textit{-O3}  sur \textit{gcc} si vous codez en C/C++. Tout cela combiné accélère le code d'un facteur 20 environ. \newline
De plus, bien que la librairire OpenMP pour paralléliser le code soit simple d'utilisation, elle gère très mal - de sa nature de mémoire partagée - les pRNG. Je conseille vivement l'utilisation de la librairie MPI qui assure une étanchéité au niveau des pRNG entre chaque thread.} 
et en le changeant légèrement vers un état $\nu$. Dans un système d'Ising, nous choisissons un spin $\sigma_i$ au hasard et regardons s'il peut être renversé ou échangé avec l'un de ses plus proches voisins. Dans le modèle SOS, nous choisissons une colonne $h_i$ au hasard et regardons s'il est possible d'ajouter ou de retirer une unité à la hauteur (c'est le nombre de particules sous l'interface au site $h_i$), ou d'échanger une particule d'une colonne vers une de ses plus proches voisins.
La différence d'énergie notée $\Delta E(\mu \rightarrow \nu)$ donne la probabilité de transition entre les deux. Si l'état final $\nu$ a une énergie inférieure à l'état initial, alors il est forcément plus probable que $\mu$, et nous acceptons le changement. Dans le cas où $E_\nu \greater E_\nu$, on accepte le changement avec une probabilité satisfaisant au bilan détaillé pour une marche markovienne satisfaint à l'état d'équilibre de Botlzmann
\begin{align}
\frac{p(\mu \rightarrow \nu)}{p(\nu \rightarrow \mu)} = e^{-\Delta Ep(\nu \rightarrow \mu)}
\end{align}
ce qui nous donne la probabilité de transition $\mu \to \nu$ de Metropolis
\begin{align}
	p(\mu \rightarrow \nu) = min(1,e^{-\beta \Delta E(\mu \rightarrow \nu)})
\end{align}
Ensuite on prend un nombre aléatoire $q$ entre $0$ et $1$. Si $q < p(\mu \rightarrow \nu)$, alors la transition est validée. Une étape de Monte Carlo est achevée lorsque $L$ tentatives de transition ont été faites. Cependant, il est possible d'accélérer l'algorithme en utilisant un temps continu \cite{newman_monte_1999} ou en prenant en compte les états dont la transition a été refusée \cite{frenkel_speed-up_2004}.
L'erreur obtenue à la fin sur notre observable $<A>$ au cours d'une simulation ayant duré $t_{max}$ étapes de Monte Carlo est 
\begin{align}
	E(A) = \sqrt{\frac{2 \tau}{t_{max}} (<A^2>-<A>^2)} 
\end{align}
Cette variance dépend du temps de corrélation $\tau$ puisque si deux micro-états sont très rapprochés dans le temps , l'observable en question n'aura pas grandement évolué. En pratique, il suffit que $\frac{\tau}{t_{max}} \less 10^{-4}$ pour obtenir une erreur inférieure à $1\%$. Ce temps de corrélation $\tau$ se calcule via la fonction d'auto-corrélation 
\begin{align}
\mC(t) = <A(t')A(t+t')>-\langle A \rangle^2 = \frac{1}{T_{max}}\int_0^{T_{max}}A(t')A(t+t')-<A>^2 dt' \simeq e^{-\frac{t}{\tau}}
\end{align}
qui se comporte comme une somme d'exponentielles, mais où dans la limite thermodynamique, seul le mode de relaxation le plus long compte\cite{wansleben_monte_1991}. En supposant la limite thermodynamique, l'ordre de grandeur de $\tau$ - et donc de la variance de nos observables - est donnée par le calcul de l'intégrale\footnote{Je recommande d'intégration de Simpson.}
\begin{align}
	\tau = \int_0^{\infty} \mC(t)/\mC(0) dt
	\label{tau_cor}
\end{align}
Le calcul de la plus grande longueur de corrélation $\xi$ du système se fait de manière analogue en intégrant la fonction de corrélation spatiale définie par
\begin{align}
\mC(x) = \frac{1}{L} \sum_{x'}^L A(x')A(x+x')-<A>^2 \simeq e^{-\frac{x}{\xi}}
\end{align}
Une discussion plus rigoureuse sur la forme de la fonction de corrélation spatiale sera donnée dans la section \ref{sec_laser}.

	\subsection{Ensemble grand-canonique : algorithme de Glauber}

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{numerical/sos-glau-eq-cor.pdf}
	\caption{Courbe de l'énergie (haut) et fonction d'auto-corrélation (bas) dans avec un \textbf{paramètre d'ordre non-conservé} à partir de la condition initiale. Le temps d'équilibrage (en étapes de Monte Carlo) diminue avec la température, tandis que le temps de corrélation reste relativement constant. Le temps de corrélation étant extrêmement faible, $10^7$ étapes de Monte Carlo suffisent à avoir une erreur de moins de $0.1\%$ sur les moyennes mesurées.}
	\label{eq-glau}
\end{figure}
	
Le dépôt de particules provenant d'un réservoir permet de faire grandir un cristal à partir d'un substrat. Ce genre de systèmes est défini par le potentiel chimique $\mu$ des particules, dans le solvant et appartient à l'ensemble grand-canonique. Dans ce cas, on choisit au hasard de manière uniforme une colonne $h_i$ dans laquelle on décide de mettre ou d'enlever une particule selon le flux de particules $\nu$ vu dans l'équation d'Edwards-Wilkinson \ref{edwards-wilkinson}. Si l'on se place à l'équilibre thermodynamique, c'est-à-dire qu'autant de particules se déposent au niveau de l'interface que de particules la quittent, alors il faut que la probabilité de ces deux événements soient égales entre elles, et donc égales à $50\%$.
Dans le cas où la géométrie est infinie, les valeurs des $h_i$ ne sont pas bornées, tandis que dans une géométrie torique de hauteur $L$, on rejette toutes les configurations qui ne respectent pas aux conditions $0 \leq h_i \leq L$.
En essayant d'aller du micro-état $\mu$ vers le micro-état $\nu$ où on a fait la transformation $h_i \rightarrow h_i + \alpha$ où $\alpha=\pm 1$, on obtient que la différence d'énergie est
\begin{align}
	\Delta E &= |h_{i-1}-(h_i \pm 1)| + |h_{i+1}-(h_i \pm 1)| - |h_{i-1}-h_i| - |h_{i+1}-h_i|  \\
		&= 2 \left( (h_i \leq h_{i-1}) + (h_i \geq h_{i+1}) -1 \right )
\end{align}
où $(h_i \leq h_{i-1})$ est un booléen valant $1$ si la condition est vraie, $0$ sinon.
Le changement de magnétisation est alors $\Delta M = \alpha$, et la largeur de l'interface, définie par $\sigma = \sum_i (h_i-h_{i+1})^2$, change comme
\begin{align}
	\Delta \sigma = 2 \alpha (h_{i+1}-h_i) + 2
\end{align}
On n'a donc pas besoin, à chaque pas de temps, de recalculer ces deux grandeurs, il suffit de les actualiser dans une variable pour avoir les observables à tout instant $t$.


Afin d'accélérer le processus d'équilibrage du système, il est recommandé de commencer directement avec la valeur moyenne de magnétisation calculée à partir de la matrice de transfert. On regarde ensuite le temps d'équilibrage par la courbe $E(t)$, en attendant d'atteindre la valeur à l'équilibre. 
À l'équilibre, le taux d'évaporation des particules doit être égal au taux de dépôt sur notre système. Cependant, en l'absence d'un potentiel qui contraint l'interface, l'interface est délocalisée, l'empêchant d'atteindre l'équilibre thermodynamique. C'est la raison pour laquelle une simulation numérique dans une dynamique de Glauber se doit toujours d'avoir un potentiel permettant d'obtenir la localisation d'une interface. 

	\subsection{Ensemble canonique : algorithme de Kawasaki}

\begin{figure}
	\centering
	\includegraphics[scale=1]{numerical/sos-kaw-eq-cor.pdf}
	\caption{Courbe de l'énergie (haut) et fonction d'auto-corrélation (bas) dans avec un \textbf{paramètre d'ordre conservé} à partir de la condition initiale. Le temps d'équilibrage (en étapes de Monte Carlo) diminue avec la température, tandis que le temps de corrélation reste relativement constant. Le temps de corrélation est similaire à la dynamique de Glauber, bien que l'équilibrage soit plus long à se faire.}
	\label{eq-kaw}
\end{figure}
	
La diffusion des particules - par exemple un polymère dans un solvant - est une dynamique locale qui conserve le paramètre d'ordre du notre système, nommément la magnétisation $m$. Dans ce cas, on choisit au hasard de manière uniforme deux colonnes $h_i$ et $h_{i+1}$ dans lesquelles on va essayer d'échanger une particule entre les deux colonnes. Afin de respecter le bilan détaillé, il faut que la probabilité de choisir le mouvement $h_i \rightarrow h_{i+1}$ soit égale à $h_{i+1} \rightarrow h_i$. On peut juste définir à nouveau "l'ajout" d'une colonne vers ou à partir de l'autre via la transformation $h_i \rightarrow h_i + \alpha$ et $h_{i+1} \rightarrow h_{i+1} - \alpha$ (avec $\alpha=\pm 1$), en respectant toujours les conditions aux bords en $y$. Trois termes dans l'énergie sont modifiées\footnote{Comme précédement, il existe une version booléenne de l'équation, mais sa longueur n'offre aucun avantage en terme d'implémentation dans le code comparé au gain de temps de CPU engendré.}
\begin{align}
	\Delta E = &|h_{i-1}-(h_i \pm 1)| + |h_{i+1} \pm 1 -(h_i \pm 1)| + |h_{i+1}\pm 1-(h_{i+2} )| \\
	- &|h_{i-1}-h_i| - |h_{i+1}-h_i| - |h_{i+1}-h_{i+2}|
\end{align}

La magnétisation totale est ainsi conservée, tandis que la largeur de l'interface $\sigma$ se calcule par
\begin{align}
	\Delta \sigma = 2 \alpha  + 1
\end{align}

	\subsection{Dynamique hors-équilibre}
L'ensemble grand-canonique ne nous permet d'avoir un système qu'à l'équilibre, puisqu'il est traduit par une dynamique non-locale. Seule une dynamique locale comme la dynamique de Kawasaki peut nous donner des états hors-équilibre. L'implémentation la plus simple est d'introduire un terme de cisaillement dans notre modèle lorsque l'on décide de bouger une particule. Ce cisaillement diminue l'énergie du micro-état lorsque la particule bouge dans un sens et l'augmente si elle bouge dans l'autre sens, ce qui brise le bilan détaillé. De nombreux travaux sur les systèmes hors-équilibre dans le modèle d'Ising ont été produits \cite{smith_interfaces_2008} présentant la diminution de la largeur de l'interface lorsque le cisaillement est produit de manière parallèle. 
On peut définir deux espèces de cisaillement parallèles.
Le premier genre de cisaillement se produit aux bords d'un liquide non-visqueux, ce qui ne permet de bouger que les particules aux bords du système : il n'est donc pas adaptable à un système infini ou semi-infini. Pour un système de taille $L$ et pour un module de cisaillement de $f$, la différence d'énergie supplémentaire est 
\begin{align}
	\Delta E_{bord} = f [ (h_i == 1 || h_{i+1} == L-1) - (h_i == L-1 || h_{i+1} == 0)  ]
\end{align}
Le second genre de cisaillement se produit aux bords d'un fluide permettant un transport visqueux, ce qui entraîne un cisaillement proportionnel à la distance aux bords comme sur la figure \ref{snap-ising-shear}. En supposant que le cisaillement est nul au niveau de l'interface et que les particules vont à gauche dans la partie basse du système (et à droite dans la partice haute du système), on obtient alors
\begin{align}
	\Delta E_{prop} = f h_i
\end{align}
Cependant, pour des raisons de facilité de calcul plus tard afin de comparer les simulations numériques aux résultats analytiques, on utilise un cisaillement uniforme qui pousse les particules dans un sens. Ce type de système correspond à un flux laminaire, par exemple dû à la gravité face à une interface verticale qui tire les particules vers le bas. La différence d'énergie devient
\begin{align}
	\Delta E_{uni} = \alpha f
\end{align}
où $\alpha = 1$ si la particule va vers la droite, $-1$ sinon. 
		
	\subsection{Modèle POP}		

Dans le modèle POP, le modèle n'est plus structuré en fonction des sites $i$ mais bien des particules $\sigma_(n) = i$, la hauteur d'un site\footnote{Cette hauteur est mise à jour à chaque étape mouvement d'une particule dans un second tableau.} devenant alors
\begin{align}
	h_i = \sum_{n=0}^N \delta_{\sigma_n,i}
\end{align}

Lors d'une dynamique de Kawasaki, à chaque étape, on choisit au hasard une particule parmi les $N$ présentes dans le système pour la déplacer d'une colonne. 

Il est également possible de donner des constantes de diffusion différentes à chaque particule\footnote{Grâce à la construction d'un générateur via \textit{random::discrete\_distribution} où chaque particule a une probabilité différente d'être sélectionnée. }  afin d'émuler différents types de particules. 

La question est plus délicate lorsqu'il s'agit d'une dynamique de Glauber. Puisque chaque particule a une probabilité d'être sélectionnée pour être détruite, comment choisir la probabilité d'ajouter une particule au système ? À l'équilibre, le flux de particules entrantes est égale au flux de particules sortantes, c'est-à-dire $p_{ajout}= p_{retrait} = 0.5\%$. Dans ce cas, il suffit de choisir un booléen au hasard, puis détruire une particule et son label ou ajouter une particule à un site particulier. L'avantage de la dynamique conservée est qu'il n'est pas nécessaire de reconstruire une distrubtion pRNG à chaque étape, même si le constructeur est rapide \footnote{Le constructeur a une complexité en $\mathcal{O}(n)$ au pire. \url{http://www.cplusplus.com/reference/random/discrete_distribution/discrete_distribution/}}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Dans ce chapitre nous avons décrit les différentes méthodes de calcul numérique qui vont de pair avec le modèle A et le modèle B, et la manière de mesurer les observables ainsi que leur barre d'erreur. Dans la pratique, les temps de corrélation sont si faibles qu'il suffit de faire environ $10^7$ étapes de Monte Carlo afin d'obtenir de bonnes statistiques, ce qui en une dimension, est extrêmement rapide. La rapidité des simulations dans le modèle SOS nous permet ainsi d'étudier une très vaste plage de paramètres, que ce soit pour différentes températures, cisaillements, hauteurs maximales ou champs externes. 
mux
